{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_ai_traditional_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCfJ7pCYoQ/ue/Im4bVUcc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philipsales/natural-language-processing-notes/blob/master/philipsales%20/%20natural-language-processing-notes/fast_ai_traditional_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVABq307gT2"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn import decomposition\n",
        "from scipy import linalg\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e6XUnu87tao"
      },
      "source": [
        "%matplotlib inline\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF_isaA-nrGP"
      },
      "source": [
        "# Summary\n",
        "1. Data Exploration\n",
        "  1. Stop Words\n",
        "    1. Stop words in SkLearn but not in Spacy\n",
        "    1. Stop words in Spacy but not in SkLearn\n",
        "  1. Stemming\n",
        "  1. Lemmatization\n",
        "  1. Spacy\n",
        "\n",
        "\n",
        "1. Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSQQougI-4x1"
      },
      "source": [
        "# Data Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_8fwg5v749R",
        "outputId": "a8f63e13-a10a-4d9d-cc43-9b991f106044"
      },
      "source": [
        "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "remove = ('headers', 'footers', 'quotes')\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEK6H8BZ92zW",
        "outputId": "93581428-d2cf-44c1-ed86-d2849451a449"
      },
      "source": [
        "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2034,), (2034,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlNJngu09-13",
        "outputId": "8ced6c72-a6b0-4767-f33a-f2ed72433f15"
      },
      "source": [
        "print(\"\\n--------\".join(newsgroups_train.data[:3]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "--------\n",
            "\n",
            "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
            "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
            "folks with him, children and all, to satisfy his delusional mania. Jim\n",
            "Jones, circa 1993.\n",
            "\n",
            "\n",
            "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
            "for centuries.\n",
            "--------\n",
            " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
            "\n",
            "MB>                                                             So the\n",
            "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
            "\n",
            "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
            "\n",
            "Couldn't we just say periapsis or apoapsis?\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF8AR-2w-IcX",
        "outputId": "0b385efb-6436-4777-e1db-38f72ddebdfa"
      },
      "source": [
        "np.array(newsgroups_train.target_names)[newsgroups_train.target[:4]]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['comp.graphics', 'talk.religion.misc', 'sci.space', 'alt.atheism'],\n",
              "      dtype='<U18')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l16evQT-diw",
        "outputId": "a14bbaf9-6c70-4471-af60-29aa12dd9c24"
      },
      "source": [
        "newsgroups_train.target[:3]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cheXp_Sh_DtH"
      },
      "source": [
        "## Stop Words, stemming, Lemmatization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_18uKgv6_ea-"
      },
      "source": [
        "### Stop words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISS8BT61_e7r",
        "outputId": "333abba5-74c6-471f-809a-ae291d80d30c"
      },
      "source": [
        "from sklearn.feature_extraction import stop_words\n",
        "\n",
        "sorted(list(stop_words.ENGLISH_STOP_WORDS))[:20]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amoungst']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCnbGw4FPmdi",
        "outputId": "4311521f-9d5e-4b46-f429-9e6b0c5afe22"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jln7lNPNPwG1"
      },
      "source": [
        "from nltk import stem"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNYAR-p4Py-M"
      },
      "source": [
        "wnl = stem.WordNetLemmatizer()\n",
        "porter = stem.porter.PorterStemmer()\n",
        "lancaster = stem.lancaster.LancasterStemmer()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRM-9EElQCb3"
      },
      "source": [
        "word_list = ['feet', 'foot', 'foots', 'footing']\n",
        "word_list = ['fly', 'flies', 'flying', 'organize', 'organizes', 'organizing', 'universe', 'university']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J95lX-TiQJm0",
        "outputId": "a7fdd7a0-634a-4c6a-9270-61335db566fd"
      },
      "source": [
        "[wnl.lemmatize(word) for word in word_list]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fly',\n",
              " 'fly',\n",
              " 'flying',\n",
              " 'organize',\n",
              " 'organizes',\n",
              " 'organizing',\n",
              " 'universe',\n",
              " 'university']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVvt1d6PQPvh",
        "outputId": "faa21179-215e-4d1b-ad46-5c77ff2b89bd"
      },
      "source": [
        "[porter.stem(word) for word in word_list]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fli', 'fli', 'fli', 'organ', 'organ', 'organ', 'univers', 'univers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sb8EzXHQQJh",
        "outputId": "7955be0d-f978-46cb-f4a3-addb037c5024"
      },
      "source": [
        "[lancaster.stem(word) for word in word_list]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fly', 'fli', 'fly', 'org', 'org', 'org', 'univers', 'univers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9_VXoG_RYw3"
      },
      "source": [
        "### Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnWy-yZfSOO1",
        "outputId": "c4d11084-621c-42ba-c5f6-8aa56b6f4a36"
      },
      "source": [
        "!pip install -U spacy\n",
        "#!spacy -m download en_core_web_sm\n",
        "#!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/b2/12466d3018bb84b039139ef76436ea7a01e98125c2aee6a81e527eb4ebe1/spacy-2.3.4-cp36-cp36m-manylinux2014_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.4)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/c9/ce2e03720a5647fd90da575325376ff258653a05f357aa970fd87e6c1a55/thinc-7.4.3-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.4 thinc-7.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2DtRLLdRvLd"
      },
      "source": [
        "import spacy\n",
        "from spacy.lemmatizer import Lemmatizer\n",
        "from spacy.lookups import Lookups\n",
        "\n",
        "lookups = Lookups()\n",
        "lemmatizer = Lemmatizer(lookups)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhC5DRmER1CO",
        "outputId": "509210f2-c2d6-45c4-869d-2cfb4b93b57f"
      },
      "source": [
        "[lemmatizer.lookup(word) for word in word_list]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fly',\n",
              " 'flies',\n",
              " 'flying',\n",
              " 'organize',\n",
              " 'organizes',\n",
              " 'organizing',\n",
              " 'universe',\n",
              " 'university']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkedCjjVU0ZV",
        "outputId": "9019cde5-4381-47ef-d2ce-fb7d97982245"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.4). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMUR5CLxVYEM",
        "outputId": "9d6a84ea-013a-4d4c-c2be-7c3664a75f7f"
      },
      "source": [
        "sorted(list(nlp.Defaults.stop_words))[:20]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'d\",\n",
              " \"'ll\",\n",
              " \"'m\",\n",
              " \"'re\",\n",
              " \"'s\",\n",
              " \"'ve\",\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDSetDPvnVU6"
      },
      "source": [
        "### Stop words in SkLearn but not in Spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiMtj02JnXfc",
        "outputId": "c691c0a6-515a-43bd-8be4-d585c0235b90"
      },
      "source": [
        "stop_words.ENGLISH_STOP_WORDS - nlp.Defaults.stop_words"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "frozenset({'amoungst',\n",
              "           'bill',\n",
              "           'cant',\n",
              "           'co',\n",
              "           'con',\n",
              "           'couldnt',\n",
              "           'cry',\n",
              "           'de',\n",
              "           'describe',\n",
              "           'detail',\n",
              "           'eg',\n",
              "           'etc',\n",
              "           'fill',\n",
              "           'find',\n",
              "           'fire',\n",
              "           'found',\n",
              "           'hasnt',\n",
              "           'ie',\n",
              "           'inc',\n",
              "           'interest',\n",
              "           'ltd',\n",
              "           'mill',\n",
              "           'sincere',\n",
              "           'system',\n",
              "           'thick',\n",
              "           'thin',\n",
              "           'un'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVbakLopnPpx"
      },
      "source": [
        "### Stop words in Spacy but not in SkLearn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpANhFH7nK-n",
        "outputId": "0ed76652-1896-420a-b7b4-c8d632908315"
      },
      "source": [
        "nlp.Defaults.stop_words - stop_words.ENGLISH_STOP_WORDS"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'d\",\n",
              " \"'ll\",\n",
              " \"'m\",\n",
              " \"'re\",\n",
              " \"'s\",\n",
              " \"'ve\",\n",
              " 'ca',\n",
              " 'did',\n",
              " 'does',\n",
              " 'doing',\n",
              " 'just',\n",
              " 'make',\n",
              " \"n't\",\n",
              " 'n‘t',\n",
              " 'n’t',\n",
              " 'quite',\n",
              " 'really',\n",
              " 'regarding',\n",
              " 'say',\n",
              " 'unless',\n",
              " 'used',\n",
              " 'using',\n",
              " 'various',\n",
              " '‘d',\n",
              " '‘ll',\n",
              " '‘m',\n",
              " '‘re',\n",
              " '‘s',\n",
              " '‘ve',\n",
              " '’d',\n",
              " '’ll',\n",
              " '’m',\n",
              " '’re',\n",
              " '’s',\n",
              " '’ve'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5509ZgZ-Ve7z",
        "outputId": "e00076e3-4580-4b24-daf2-95ae24632371"
      },
      "source": [
        "doc = nlp(u\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "a\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WwNeEisYeCF",
        "outputId": "4ebe8795-b41a-4b23-c6ad-7d804b7bec9b"
      },
      "source": [
        "doc = nlp(u\"The striped bats are hanging on their feet for best\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.lemma_)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "stripe\n",
            "bat\n",
            "be\n",
            "hang\n",
            "on\n",
            "-PRON-\n",
            "foot\n",
            "for\n",
            "good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX4wpRjAX-8O",
        "outputId": "9d82c0e5-5017-41ce-ac31-8d8da9e3916b"
      },
      "source": [
        "for word in doc:\n",
        "    print(word.text, word.pos_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DET\n",
            "striped VERB\n",
            "bats NOUN\n",
            "are AUX\n",
            "hanging VERB\n",
            "on ADP\n",
            "their DET\n",
            "feet NOUN\n",
            "for ADP\n",
            "best ADJ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBXKEMIYLSl",
        "outputId": "ee940a95-2674-452c-d4b9-a44d3d2e9485"
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(u\"My name is Jeff.\")\n",
        "displacy.serve(doc, style=\"dep\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5S6Llm3ZFFw"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkxptEs8ZGcf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enCl39KVZhAj"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E31gI5qypxjo"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi7JKWlep2RF",
        "outputId": "9dac7761-e72b-4e7f-b08c-e6812846bf84"
      },
      "source": [
        "vectors = vectorizer.fit_transform(newsgroups_test.data).todense()\n",
        "vectors"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Caiuc41gp7yv",
        "outputId": "9fae9d66-a9f7-4a2f-dff7-c5b53e88a897"
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1353, 21240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}